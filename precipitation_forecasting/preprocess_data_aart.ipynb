{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pysteps configuration file found at: /usr/people/schreurs/.local/lib/python3.9/site-packages/pysteps/pystepsrc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import re\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "from batchcreator import minmax\n",
    "from batchcreator import DataGenerator as dg\n",
    "import tensorflow as tf\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aart Radar Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_aart = '/nobackup_1/users/schreurs/project_GAN/dataset_aart'\n",
    "\n",
    "folders = sorted([f for f in os.listdir(path_aart) if os.path.isdir(os.path.join(path_aart, f))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpack zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zip path:  /nobackup/users/schreurs/project_GAN/dataset_aart/2009/2009.zip\n",
      "unpack in folder:  /nobackup/users/schreurs/project_GAN/dataset_aart/2009\n"
     ]
    }
   ],
   "source": [
    "# Testing path\n",
    "zip_path = path_aart + '/' + folders[0] + '/' + folders[0] + '.zip'\n",
    "print(\"zip path: \", zip_path)\n",
    "unpack_folder = path_aart + '/' + folders[0]\n",
    "print(\"unpack in folder: \", unpack_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip():\n",
    "    for folder in tqdm(folders):\n",
    "        zip_path = path_aart + '/' + folder + '/' + folder + '.zip'\n",
    "        unpack_folder = path_aart + '/' + folder\n",
    "\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_file:\n",
    "            zip_file.extractall(unpack_folder)\n",
    "#unzip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert NC to npy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy arrays take more memory than nc files. Therefor I will only convert 1 year of data to numpy for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filesnames(start_dt, end_dt):\n",
    "    '''\n",
    "    This function returns filenames between the a starting date and end date. \n",
    "    start_dt: starting date time \n",
    "    end_dt: end date time\n",
    "    '''\n",
    "    # Create list of IDs to retrieve\n",
    "    dts = np.arange(start_dt, end_dt, timedelta(minutes=5)).astype(datetime)\n",
    "    # Convert to filenames\n",
    "    filenames = ['{:%Y%m%d%H%M}'.format(dt) for dt in dts]\n",
    "    return filenames \n",
    "\n",
    "def nc2npy(in_path, out_path, year=2018, overwrite=False, preprocess=False, filenames=None):\n",
    "    '''\n",
    "    Converts nc files of a given year to numpy files \n",
    "    in_path: path that points to the .nc files\n",
    "    out_path: directory to store numpy files\n",
    "    year: indicates which year to convert\n",
    "    as_int: converts the decimal numbers to integers. \n",
    "            Note that the data is discrete, therefor integers might be more suitable than floats\n",
    "    overwrite: If true then overwrite previously preprocessed data. If false, then skips files that\n",
    "                are already preprocessed\n",
    "    preprocess: If true then preprocesses the data by converting rain to dbz, normalize to [0,1] and rescale to 256x256\n",
    "    '''   \n",
    "    if filenames is not None:\n",
    "        out_path = config.dir_aart_prep\n",
    "    else:\n",
    "        # Get filename of corresponding year\n",
    "        start = datetime(year, 1, 1, 0, 0)\n",
    "        end = datetime(year,12, 31, 23, 55)\n",
    "        filenames = get_filesnames(start,end)\n",
    "        \n",
    "    # Create directory if it does not exist\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "    for filename in tqdm(filenames): \n",
    "        year_str = filename[:4]\n",
    "        path_f = in_path + year_str + '/' + config.prefix_aart + filename + '.nc'\n",
    "        \n",
    "        if not overwrite and filename +'.npy' in output_files:\n",
    "            # Skip this file if already processed,\n",
    "            # go to next file in list\n",
    "            continue\n",
    "        try:\n",
    "            with Dataset(path_f, mode='r') as ds:\n",
    "                rain = ds['image1_image_data'][:][0].data\n",
    "                mask = ds['image1_image_data'][:][0].mask\n",
    "                \n",
    "                # Apply mask\n",
    "                rain = rain * ~mask\n",
    "                # convert to mm/h from mm/5min\n",
    "                rain = rain*12\n",
    "                if preprocess:\n",
    "                    rain = perform_preprocessing(rain)  \n",
    "            np.save(out_path + '/{}.npy'.format(filename), rain)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_preprocessing(y, downscale256=True):\n",
    "    # convert to dbz and perform normalize to values between 0 and 1\n",
    "    y = minmax(y, norm_method='minmax', undo=False, convert_to_dbz = True)\n",
    "    \n",
    "    y = np.expand_dims(y, axis=-1)\n",
    "    if downscale256:\n",
    "        # Temporary expand y dimensions so that cropping function works: h,w,c -> 1,1,h,w,c\n",
    "        y = np.expand_dims(y, axis=0)\n",
    "        y = np.expand_dims(y, axis=0)\n",
    "        # First make the images square size\n",
    "        y = dg.crop_center(dg, y, cropx=384, cropy=384) \n",
    "        \n",
    "        # Remove the extra dimensions \n",
    "        y = y[0][0]\n",
    "        y =  tf.image.resize(y, (256, 256))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70462\n",
      "Approx 0.67 years of data\n"
     ]
    }
   ],
   "source": [
    "path_aart = config.dir_aart\n",
    "path_aart_prep = config.dir_aart_prep\n",
    "\n",
    "# Get files that are already converted to numpy\n",
    "output_files = sorted([f for f in os.listdir(path_aart_prep) \n",
    "                       if os.path.isfile(os.path.join(path_aart_prep, f))])\n",
    "\n",
    "print(len(output_files))\n",
    "print('Approx {:.2f} years of data'.format(len(output_files)/288/365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221025\n",
      "80710\n",
      "200801031330 201912301330\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data of the 30minute interval with 3 y\n",
    "# Load all target files in the training set\n",
    "fn_aart_train = np.load('datasets/train2008_2018_3y_30m.npy', allow_pickle = True)[:,1]\n",
    "fn_aart_val = np.load('datasets/val2019_3y_30m.npy', allow_pickle = True)[:,1]\n",
    "filenames_aart = np.append(fn_aart_train, fn_aart_val)\n",
    "\n",
    "# flatten the list\n",
    "filenames_aart = [item for sublist in filenames_aart for item in sublist]\n",
    "print(len(filenames_aart))\n",
    "# remove duplicate filenames:\n",
    "filenames_aart = sorted(list(set(filenames_aart)))\n",
    "print(len(filenames_aart))\n",
    "print(filenames_aart[0], filenames_aart[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 62324/80710 [00:25<00:15, 1202.21it/s] <ipython-input-3-a0b9e8099cb8>:46: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  rain = ds['image1_image_data'][:][0].data\n",
      "<ipython-input-3-a0b9e8099cb8>:47: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask = ds['image1_image_data'][:][0].mask\n",
      "100%|██████████| 80710/80710 [12:37<00:00, 106.53it/s] \n"
     ]
    }
   ],
   "source": [
    "nc2npy(path_aart, path_aart_prep, overwrite = False, preprocess=True, filenames=filenames_aart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 3y dataset to 1y\n",
    "data = np.load('train2015_2018_3y_30m.npy', allow_pickle = True)\n",
    "y = [[ys[0]] for ys in data[:,1]]\n",
    "data[:,1] = y\n",
    "np.save('train2015_2018_1y_30m.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 3y dataset to 1y\n",
    "data = np.load('val2019_3y_30m.npy', allow_pickle = True)\n",
    "y = [[ys[0]] for ys in data[:,1]]\n",
    "data[:,1] = y\n",
    "np.save('val2019_1y_30m.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('train2008_2018_3y_30m.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25409, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('datasets/train2015_2018_3y_30m.npy', allow_pickle = True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10493, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9351, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without2008 = []\n",
    "\n",
    "for sample in data:\n",
    "    if not sample[1][0][:4] == '2008':\n",
    "        without2008.append(sample)\n",
    "without2008 = np.array(without2008)\n",
    "without2008.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['200901180135', '200901180140', '200901180145', '200901180150', '200901180155', '200901180200']),\n",
       "       list(['200901180230', '200901180300', '200901180330'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without2008[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train2009_2018_3y_30m.npy', without2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/03/202003271505.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/07/202007160430.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/07/202007160435.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/10/202010011130.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/10/202010062040.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/10/202010190845.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/10/202010200020.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011020000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011030000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011040000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011050000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011060000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011070000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011080000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011100000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011110000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011120000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011130000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011140000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011150000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011160000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011170000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011180000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011190000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011200000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011210000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011230000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011260000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011270000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011270910.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/11/202011280000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012010000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012020000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012030000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012040000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012050000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012060000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012070000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012110000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012120000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012150000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012160000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012170000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012170810.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012200000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012210000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012220000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012240000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012270000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012280000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012300000.npy'\n",
      "[Errno 2] No such file or directory: '/nobackup_1/users/schreurs/project_GAN/rtcor_heavy_rain_labels/2020/12/202012310000.npy'\n",
      "(['202012271435', '202012271440', '202012271445', '202012271450', '202012271455', '202012271500'], ['202012271530', '202012271600', '202012271630'])\n",
      "861\n"
     ]
    }
   ],
   "source": [
    "from batchcreator import get_list_IDs\n",
    "\n",
    "# for testing preprocess some more files with different y interval setttings\n",
    "start_dt = datetime(2020,1,1,0,0)\n",
    "end_dt =  datetime(2021,1,1,0,0)\n",
    "\n",
    "list_IDs = get_list_IDs(start_dt, end_dt, x_seq_size=6, y_seq_size=3, filter_no_rain='avg0.01mm', y_interval=30)\n",
    "print(list_IDs[-1])\n",
    "print(len(list_IDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2304/67153 [00:00<00:02, 23034.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 7105/67153 [00:00<00:02, 23811.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2008/08/RAD_NL25_RAC_5M_200808150730.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2008/08/RAD_NL25_RAC_5M_200808150730.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2008/08/RAD_NL25_RAC_5M_200808150730.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2008/09/RAD_NL25_RAC_5M_200809231200.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2008/09/RAD_NL25_RAC_5M_200809231200.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2008/09/RAD_NL25_RAC_5M_200809231330.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2008/09/RAD_NL25_RAC_5M_200809231400.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2008/09/RAD_NL25_RAC_5M_200809231330.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2008/09/RAD_NL25_RAC_5M_200809231400.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2008/10/RAD_NL25_RAC_5M_200810080800.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2008/10/RAD_NL25_RAC_5M_200810080800.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2008/10/RAD_NL25_RAC_5M_200810080800.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 19285/67153 [00:01<00:02, 16909.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2010/05/RAD_NL25_RAC_5M_201005310000.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2010/05/RAD_NL25_RAC_5M_201005310000.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2010/05/RAD_NL25_RAC_5M_201005310030.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2010/05/RAD_NL25_RAC_5M_201005310000.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2010/05/RAD_NL25_RAC_5M_201005310030.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2010/05/RAD_NL25_RAC_5M_201005310100.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 22420/67153 [00:01<00:06, 6735.61it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2011/04/RAD_NL25_RAC_5M_201104041500.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2011/04/RAD_NL25_RAC_5M_201104041530.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2011/04/RAD_NL25_RAC_5M_201104041600.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 30135/67153 [00:03<00:04, 7503.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2012/05/RAD_NL25_RAC_5M_201205160600.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 31791/67153 [00:03<00:04, 7646.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2012/08/RAD_NL25_RAC_5M_201208140830.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2012/08/RAD_NL25_RAC_5M_201208140830.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2012/08/RAD_NL25_RAC_5M_201208140830.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 33749/67153 [00:03<00:04, 8113.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2012/11/RAD_NL25_RAC_5M_201211061230.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2012/11/RAD_NL25_RAC_5M_201211061230.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 35326/67153 [00:03<00:04, 6838.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2013/02/RAD_NL25_RAC_5M_201302091500.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2013/02/RAD_NL25_RAC_5M_201302091500.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2013/02/RAD_NL25_RAC_5M_201302091500.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 45950/67153 [00:04<00:01, 12332.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2014/08/RAD_NL25_RAC_5M_201408121330.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2014/08/RAD_NL25_RAC_5M_201408121330.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2014/08/RAD_NL25_RAC_5M_201408121330.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2014/08/RAD_NL25_RAC_5M_201408261330.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2014/08/RAD_NL25_RAC_5M_201408261330.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2014/08/RAD_NL25_RAC_5M_201408261330.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 50176/67153 [00:05<00:03, 4982.05it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2015/06/RAD_NL25_RAC_5M_201506230530.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2015/06/RAD_NL25_RAC_5M_201506230530.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2015/06/RAD_NL25_RAC_5M_201506230530.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2015/07/RAD_NL25_RAC_5M_201507291600.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2015/07/RAD_NL25_RAC_5M_201507291600.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 52394/67153 [00:05<00:02, 5718.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2015/09/RAD_NL25_RAC_5M_201509141730.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2015/09/RAD_NL25_RAC_5M_201509141730.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2015/09/RAD_NL25_RAC_5M_201509141800.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2015/09/RAD_NL25_RAC_5M_201509141730.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2015/09/RAD_NL25_RAC_5M_201509141800.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2015/09/RAD_NL25_RAC_5M_201509141830.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 61808/67153 [00:07<00:00, 5994.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2017/03/RAD_NL25_RAC_5M_201703180430.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2017/03/RAD_NL25_RAC_5M_201703180430.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2017/03/RAD_NL25_RAC_5M_201703180430.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2017/03/RAD_NL25_RAC_5M_201703180530.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2017/03/RAD_NL25_RAC_5M_201703181400.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 63796/67153 [00:07<00:00, 4102.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2017/05/RAD_NL25_RAC_5M_201705201500.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2017/05/RAD_NL25_RAC_5M_201705201500.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2017/05/RAD_NL25_RAC_5M_201705201500.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2017/07/RAD_NL25_RAC_5M_201707191800.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 65889/67153 [00:08<00:00, 6565.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2017/08/RAD_NL25_RAC_5M_201708021200.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2017/08/RAD_NL25_RAC_5M_201708021200.h5\n",
      "/nobackup_1/users/schreurs/project_GAN/dataset_rtcor2/2017/08/RAD_NL25_RAC_5M_201708021200.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67153/67153 [00:08<00:00, 8025.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import config as conf\n",
    "list_IDs2 = []\n",
    "print(len(list_IDs))\n",
    "for io in tqdm(list_IDs):\n",
    "    add = True\n",
    "    for fs in io:\n",
    "        for f in fs:\n",
    "            year = f[:4]\n",
    "            month = f[4:6]\n",
    "            ts = f\n",
    "            f_path = conf.dir_rtcor + '{Y}/{m}/{prefix}{ts}.h5'.format(Y=year, m=month, ts=ts, prefix=conf.prefix_rtcor)\n",
    "\n",
    "            if not os.path.isfile(f_path):\n",
    "                print(f_path)\n",
    "                add = False\n",
    "    if add:\n",
    "        list_IDs2.append(io)\n",
    "\n",
    "print(len(list_IDs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/people/schreurs/.local/lib/python3.9/site-packages/numpy/core/_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "np.save('datasets/train2008_2018_3y_30m', list_IDs2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
